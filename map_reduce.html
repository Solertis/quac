

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>4. Map-Reduce with QUACreduce &mdash; QUAC documentation for commit cdafde4</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="QUAC documentation for commit cdafde4" href="index.html" />
    <link rel="next" title="5. Configuration" href="config.html" />
    <link rel="prev" title="3. Preprocessing" href="pipeline.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="config.html" title="5. Configuration"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="pipeline.html" title="3. Preprocessing"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">QUAC documentation for commit cdafde4</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4. Map-Reduce with QUACreduce</a><ul>
<li><a class="reference internal" href="#introduction">4.1. Introduction</a></li>
<li><a class="reference internal" href="#summary-of-api">4.2. Summary of API</a></li>
<li><a class="reference internal" href="#example">4.3. Example</a><ul>
<li><a class="reference internal" href="#create-sample-input">4.3.1. Create sample input</a></li>
<li><a class="reference internal" href="#define-the-map-operator">4.3.2. Define the <em>map</em> operator</a></li>
<li><a class="reference internal" href="#define-the-reduce-operator">4.3.3. Define the <em>reduce</em> operator</a></li>
<li><a class="reference internal" href="#test-the-operators-together">4.3.4. Test the operators together</a></li>
<li><a class="reference internal" href="#prepare-the-job">4.3.5. Prepare the job</a></li>
<li><a class="reference internal" href="#run-the-job-with-make">4.3.6. Run the job with make</a></li>
<li><a class="reference internal" href="#run-the-job-with-slurm">4.3.7. Run the job with SLURM</a></li>
<li><a class="reference internal" href="#add-more-input-data">4.3.8. Add more input data</a></li>
<li><a class="reference internal" href="#what-s-next">4.3.9. What&#8217;s next?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#drawbacks">4.4. Drawbacks</a></li>
<li><a class="reference internal" href="#fixme">4.5. FIXME</a></li>
<li><a class="reference internal" href="#footnotes">4.6. Footnotes</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="pipeline.html"
                        title="previous chapter">3. Preprocessing</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="config.html"
                        title="next chapter">5. Configuration</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="map-reduce-with-quacreduce">
<h1>4. Map-Reduce with QUACreduce<a class="headerlink" href="#map-reduce-with-quacreduce" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>4.1. Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/MapReduce">Map-reduce</a> is a neat and easy to
use parallel programming paradigm. <a class="footnote-reference" href="#id5" id="id1">[1]</a> However, its implementations have some
issues:</p>
<ul class="simple">
<li>Industrial strength map-reduce frameworks (e.g., <a class="reference external" href="http://en.wikipedia.org/wiki/Apache_Hadoop">Hadoop</a>, <a class="reference external" href="http://discoproject.org/">Disco</a>) are difficult to install and use.</li>
<li>Frameworks tend to assume node-local storage. However, traditional HPC
clusters tend to have a fast parallel filesystem like <a class="reference external" href="http://www.panasas.com/products/panfs">Panasas</a>; node-local storage, if present,
typically does not persist between jobs. <a class="footnote-reference" href="#id6" id="id2">[2]</a></li>
<li>Map-reduce jobs cannot be run incrementally; if new input data are added,
the entire job must be re-run.</li>
</ul>
<p>QUACreduce is a simple wrapper included with QUAC that solves these
problems: it is designed for a fast filesystem shared by all nodes and can
take advantage of nonpersistent node-local storage. It runs on top of <tt class="docutils literal"><span class="pre">make</span></tt>
for incremental processing and works on both a single node as well as in a
SLURM allocation.</p>
</div>
<div class="section" id="summary-of-api">
<h2>4.2. Summary of API<a class="headerlink" href="#summary-of-api" title="Permalink to this headline">¶</a></h2>
<p>The basic paradigm is that map and reduce operators produce and accept
line-oriented input, with key and value separated by a single tab character.
<a class="footnote-reference" href="#id7" id="id3">[3]</a> All characters except tab, return, and newline are permitted in keys and
values (though this is untested). Null values are permitted; in this case the
separating tab may or may be omitted. <a class="footnote-reference" href="#id8" id="id4">[4]</a></p>
<p>The <tt class="docutils literal"><span class="pre">quacreduce</span></tt> command implements this API by creating a makefile, which
you then run with <tt class="docutils literal"><span class="pre">make</span></tt> (either directly or wrapped).</p>
<p>QUACreduce also has a Python API which we do not cover here.</p>
</div>
<div class="section" id="example">
<h2>4.3. Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>This example implements a toy version of the classic &#8220;word count&#8221; example
using standard UNIX tools.</p>
<div class="section" id="create-sample-input">
<h3>4.3.1. Create sample input<a class="headerlink" href="#create-sample-input" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><pre>$ echo -e 'foo bar baz\nfoo foo' &gt; /tmp/foo1.txt
$ echo -e 'bar' &gt; /tmp/foo2.txt
$ cat /tmp/foo*.txt
foo bar baz
foo foo
bar</pre>
</div>
</div>
<div class="section" id="define-the-map-operator">
<h3>4.3.2. Define the <em>map</em> operator<a class="headerlink" href="#define-the-map-operator" title="Permalink to this headline">¶</a></h3>
<p>This converts standard input into a sequence of key/value pairs, one per line.</p>
<p>We will use <tt class="docutils literal"><span class="pre">tr</span></tt> for this:</p>
<div class="highlight-python"><pre>$ cat /tmp/foo*.txt | tr '[:blank:]' '\n'
foo
bar
baz
foo
foo
bar</pre>
</div>
<p>(Note that in the standard map-reduce word count examples, the mapper emits
the value 1 for each word. QUACreduce is perfectly happy with null values,
and counting the length of a set is the same as summing a set of 1&#8217;s of the
same size, so we do the former.)</p>
</div>
<div class="section" id="define-the-reduce-operator">
<h3>4.3.3. Define the <em>reduce</em> operator<a class="headerlink" href="#define-the-reduce-operator" title="Permalink to this headline">¶</a></h3>
<p>This converts a sequence of key/value pairs from
the mapper, presented on standard input, into arbitrary output (typically
one output item per set of identical keys). All input pairs with the same
key are adjacent in the input, but there are otherwise no input ordering
guarantees.</p>
<p>We will use <tt class="docutils literal"><span class="pre">uniq</span></tt> to print each input word with the number of times it
occurred:</p>
<div class="highlight-python"><pre>$ echo -e 'b\nb\na\nc\nc\nc' | uniq -c
2 b
1 a
3 c</pre>
</div>
</div>
<div class="section" id="test-the-operators-together">
<h3>4.3.4. Test the operators together<a class="headerlink" href="#test-the-operators-together" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><pre>$ cat /tmp/foo*.txt | tr '[:blank:]' '\n' | sort -sk1 -t '    ' | uniq -c
2 bar
1 baz
3 foo</pre>
</div>
<p>Congratulations, you&#8217;ve just run map-reduce in serial mode, with one mapper
and one reducer! The next step is to run lots of mappers and reducers in
parallel, which is one thing QUACreduce helps with.</p>
</div>
<div class="section" id="prepare-the-job">
<h3>4.3.5. Prepare the job<a class="headerlink" href="#prepare-the-job" title="Permalink to this headline">¶</a></h3>
<p>The <tt class="docutils literal"><span class="pre">quacreduce</span></tt> command is used to prepare a makefile as well as a SLURM
job file:</p>
<div class="highlight-python"><pre>$ quacreduce --map 'tr "[:blank:]" "\n"' \
             --reduce 'uniq -c &gt; out/%(RID)' \
             --partitions 2 \
             /tmp/mrjob /tmp/foo*.txt</pre>
</div>
<p>What&#8217;s going on here?</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">--map</span></tt> defines the map operator. This can be any shell pipeline; watch
quoting carefully! The CWD is the job directory.</li>
<li><tt class="docutils literal"><span class="pre">--reduce</span></tt> defines the reduce operator. The variable <tt class="docutils literal"><span class="pre">%(RID)</span></tt> is the
reducer ID; this is important for keeping output from different reducers
separate. It is substituted by QUACreduce during job construction.</li>
<li><tt class="docutils literal"><span class="pre">--partitions</span></tt> defines the number of partitions. There is one reducer per
partition, so this limits the available parallelism for the reduce step (as
well as downstream map-reduce jobs unless you take other measures). The
limiting factor to keep in mind is that if you have <span class="math">\(n\)</span> input files
and <span class="math">\(p\)</span> partitions, you will need <span class="math">\(n \times p\)</span> temporary files,
which can grow quickly.</li>
<li><tt class="docutils literal"><span class="pre">/tmp/mrjob</span></tt> is a directory in which to build the job.</li>
<li><tt class="docutils literal"><span class="pre">/tmp/foo*.txt</span></tt> are the input files. There should be lots of these, as
only one mapper is run per input file. They can live anywhere but must
have unique filenames even if they are in multiple directories.</li>
</ul>
</div>
<div class="section" id="run-the-job-with-make">
<h3>4.3.6. Run the job with make<a class="headerlink" href="#run-the-job-with-make" title="Permalink to this headline">¶</a></h3>
<p>This approach is simpler but is limited to the parallelism available in a
single machine. If you need more, you can use a SLURM cluster (see the next
step). For example:</p>
<div class="highlight-python"><pre>$ cd /tmp/mrjob
$ ls -R
.:
Makefile  slurm_job  out  tmp

./out:

./tmp:</pre>
</div>
<p>QUACreduce has created two files and two directories:</p>
<ul>
<li><p class="first"><tt class="docutils literal"><span class="pre">Makefile</span></tt> is what you expect; it defines the dependency graph among
the temporary and job management files.</p>
<p><strong>Note:</strong> Output files created by your reduce operator are <em>not</em> included
in the dependency graph. Therefore, Make has no idea if they are complete
or not, so it&#8217;s your responsibility to make sure they&#8217;re not corrupted on
re-runs (which may include new data). It&#8217;s best practice to simply
overwrite these each time the reducer is run.</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">slurm_job</span></tt> is a SLURM batch file to run the Make job on multiple
nodes.</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">tmp</span></tt> is a directory containing various files used to contain
intermediate results and manage job progress. <tt class="docutils literal"><span class="pre">make</span> <span class="pre">clean</span></tt> deletes
everything in this directory.</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">out</span></tt> is a convenience directory for your use. You don&#8217;t have to put your
output here, but you ought to have a good reason not to. <tt class="docutils literal"><span class="pre">make</span>
<span class="pre">reallyclean</span></tt> deletes everything here as well as in <tt class="docutils literal"><span class="pre">tmp</span></tt>.</p>
</li>
</ul>
<p>You are now ready to run the job:</p>
<div class="highlight-python"><pre>$ make -j2
[...FIXME...]
$ ls -R
.:
Makefile  out  slurm_job  tmp

./out:
0  1

./tmp:
0.reduced  foo1.txt.0  foo1.txt.mapped  foo2.txt.1
1.reduced  foo1.txt.1  foo2.txt.0       foo2.txt.mapped</pre>
</div>
<p>Note that the subdirectories are now populated.</p>
<p>Your output is available with:</p>
<div class="highlight-python"><pre>$ cat out/*
2 bar
1 baz
3 foo</pre>
</div>
<p>Note that the output order has changed. In general, you must sort yourself
if you care about this order.</p>
</div>
<div class="section" id="run-the-job-with-slurm">
<h3>4.3.7. Run the job with SLURM<a class="headerlink" href="#run-the-job-with-slurm" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><pre>$ sbatch -N2 slurm_job -j4</pre>
</div>
<p>Note that the number of nodes requested from SLURM and <tt class="docutils literal"><span class="pre">-j</span></tt>, which is the
total number of tasks <tt class="docutils literal"><span class="pre">make</span></tt> will run simultaneously, must be coordinated
for good performance. The above might be appropriate for a cluster with two
cores per node. Memory could be a limitation also, along with myriad others.</p>
</div>
<div class="section" id="add-more-input-data">
<h3>4.3.8. Add more input data<a class="headerlink" href="#add-more-input-data" title="Permalink to this headline">¶</a></h3>
<p>One of the neat things that QUACreduce can do is add additional data
and then only re-run the parts of the job that are affected. For example:</p>
<div class="highlight-python"><pre>$ echo 'qux' &gt; /tmp/foo3.txt
$ cd /tmp/mrjob
$ quacreduce --update . /tmp/foo*.txt
$ make -j2
[...FIXME...]
$ cat out/*
2 bar
1 baz
3 foo
1 qux</pre>
</div>
<p>Note that only <tt class="docutils literal"><span class="pre">foo3.txt</span></tt> was mapped, because we already had mapper results
for <tt class="docutils literal"><span class="pre">foo1.txt</span></tt> and <tt class="docutils literal"><span class="pre">foo2.txt</span></tt>.</p>
</div>
<div class="section" id="what-s-next">
<h3>4.3.9. What&#8217;s next?<a class="headerlink" href="#what-s-next" title="Permalink to this headline">¶</a></h3>
<p>For further help, say <tt class="docutils literal"><span class="pre">quacreduce</span> <span class="pre">--help</span></tt> or see <tt class="docutils literal"><span class="pre">makr/grep.py</span></tt> for a
Python example.</p>
</div>
</div>
<div class="section" id="drawbacks">
<h2>4.4. Drawbacks<a class="headerlink" href="#drawbacks" title="Permalink to this headline">¶</a></h2>
<p>QUACreduce is pretty simple and has a number of limitations. If these are
a problem, perhaps you are better off with something else. Some of these could
be fixed, and others are more fundamental.</p>
<ul class="simple">
<li>Lower fault tolerance. If one of your nodes goes down, the job will stop.
However, it will probably do so in a consistent state, and restarting will
continue more or less where you left off.</li>
<li>Line-oriented I/O. You are responsible for serializing your data to
something without newlines, which is kind of annoying and wastes spacetime.</li>
<li>Scaling is not as good. If you need to run 10,000 mappers in parallel,
QUACreduce is probably not for you.</li>
<li>As mentioned earlier, input filenames must be unique even if they came from
different directories.</li>
<li>No automatic chunking of input; QUACreduce cannot map a single file in
parallel.</li>
</ul>
</div>
<div class="section" id="fixme">
<h2>4.5. FIXME<a class="headerlink" href="#fixme" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>sort tmpdir</li>
<li>parallel sorts</li>
</ul>
</div>
<div class="section" id="footnotes">
<h2>4.6. Footnotes<a class="headerlink" href="#footnotes" title="Permalink to this headline">¶</a></h2>
<table class="docutils footnote" frame="void" id="id5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>I know that it&#8217;s usually spelled MapReduce, but I think InterCapping is
stupid.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>This is because (a) it&#8217;s difficult to ensure that a new job is assigned
exactly the same set of nodes as a previous job and/or (b) node-local
storage is explicitly wiped between jobs.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>This is the same as Hadoop Streaming; the goal is to make QUACreduce
components with non-null values work without modification in that
framework, though this is untested.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[4]</a></td><td>Note that this contrasts with Hadoop Streaming, where a null key is
permitted but a null value isn&#8217;t.</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="config.html" title="5. Configuration"
             >next</a></li>
        <li class="right" >
          <a href="pipeline.html" title="3. Preprocessing"
             >previous</a> |</li>
        <li><a href="index.html">QUAC documentation for commit cdafde4</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012-2013, Los Alamos National Security, LLC and others.
    </div>
  </body>
</html>