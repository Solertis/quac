#!/usr/bin/env python
"""
Simulate active learning using prior knowledge about the distribution of the
positive class over time.
"""
import sys
import testable

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets
from sklearn import linear_model
from sklearn import metrics
from sklearn.naive_bayes import MultinomialNB

import quacpath
import u

ap = u.ArgumentParser(description=__doc__, epilog='')
gr = ap.default_group
gr.add_argument("--days",
                metavar='N',
                type=int,
                default=30,
                help="number of days",
                )
gr.add_argument("--iters",
                metavar='N',
                type=int,
                default=100,
                help="number of active learning iterations",
                )
gr.add_argument("--mean",
                metavar='N',
                type=float,
                default=.1,
                help="mean of positive examples by day",
                )
gr.add_argument('--strategy',
                metavar='S',
                default='random',
                help='name of function to select next instance to label')
gr.add_argument("--trials",
                metavar='N',
                type=int,
                default=20,
                help="number of active learning trials to average",
                )
gr.add_argument("--variance",
                metavar='N',
                type=float,
                default=.01,
                help="variance of positive examples by day",
                )

def sample_by_label(n, X, y, label, rand=12345):
   """
   >>> ind = sample_by_label(2, np.array([[1], [2], [3], [4]]), np.array([0, 1, 0, 1]), 0)
   >>> [i == 0 or i == 2 for i in ind]
   [True, True]
   """
   pool = [i for i in range(len(y)) if y[i] == label]
   u.rand.shuffle(pool)
   return list(np.array(pool)[:n])


def generate_examples(nsamples, nfeatures, ndays,
                      daily_positive_priors, rand=12345, ninformative=2,
                      nclusters_per_class=2):
   """
   >>> data = generate_examples(4, 10, 2, [.5, 1])
   >>> sum(data[0][1]) == 1
   True
   >>> sum(data[1][1]) == 2
   True
   """
   X_all, y_all = datasets.make_classification(n_samples=nsamples,
                                               n_features=nfeatures,
                                               n_informative=ninformative,
                                               n_clusters_per_class=nclusters_per_class,
                                               random_state=rand)
   samples_per_day = 1. * nsamples / ndays
   data_by_day = []
   for prior in daily_positive_priors:
      npos = samples_per_day * prior
      nneg = samples_per_day - npos
      pos_ind = sample_by_label(npos, X_all, y_all, 1)
      neg_ind = sample_by_label(nneg, X_all, y_all, 0)
      data_by_day.append([X_all[pos_ind + neg_ind], y_all[pos_ind + neg_ind]])
   return data_by_day


def balanced(unlabeled, clf):
   """
   Cheat and select a positive or negative example uniformly at random.
   """
   label = u.rand.randint(0, 1)
   dayi = u.rand.randint(0, len(unlabeled) - 1)
   while not any(l == label for l in unlabeled[dayi][1]):
      dayi = u.rand.randint(0, len(unlabeled) - 1)
   instancei = np.where(unlabeled[dayi][1] == label)[0][0]
   x, y = pop_instance(unlabeled, dayi, instancei)
   return x, y


def pop_instance(data, dayi, instancei):
   x = data[dayi][0][instancei]
   y = data[dayi][1][instancei]
   data[dayi][0] = np.delete(data[dayi][0], instancei, axis=0)
   data[dayi][1] = np.delete(data[dayi][1], instancei)
   return x, y


def random(unlabeled, clf):
   """
   >>> data = [[np.array([[1], [2]]), [0, 1]]]
   >>> x, y = random(data, None)
   >>> sorted(np.append(data[0][1], y))
   [0, 1]
   """
   # select non-empty day
   dayi = u.rand.randint(0, len(unlabeled) - 1)
   while len(unlabeled[dayi][0]) == 0:
      dayi = u.rand.randint(0, len(unlabeled) - 1)

   # select instance
   instancei = u.rand.randint(0, len(unlabeled[dayi][1]) - 1)
   x, y = pop_instance(unlabeled, dayi, instancei)
   return x, y


def uncertainty(unlabeled, clf):
   """ Select day at random, then select instance with least certain
   classification (i.e., closest to 0.5) """
   # FIXME: search over all days
   # select non-empty day
   dayi = u.rand.randint(0, len(unlabeled) - 1)
   while len(unlabeled[dayi][0]) == 0:
      dayi = u.rand.randint(0, len(unlabeled) - 1)

   # select instance
   scores = [abs(c[0] - 0.5)  for c in clf.predict_proba(unlabeled[dayi][0])]
   instancei = np.argmin(scores)
   x, y = pop_instance(unlabeled, dayi, instancei)
   return x, y



def active_learn(unlabeled, labeled, test_data, clf, strategy, iters):
   accuracies = []
   for iteri in range(iters):
      x, y = strategy(unlabeled, clf)
      labeled[0] = np.concatenate((labeled[0], [x]), axis=0)
      labeled[1] = np.append(labeled[1], y)
      clf.fit(labeled[0], labeled[1])
      # acc = metrics.accuracy_score(test_data[1], clf.predict(test_data[0]))
      # acc = metrics.f1_score(test_data[1], clf.predict(test_data[0]))
      acc = metrics.roc_auc_score(test_data[1], [p[1] for p in clf.predict_proba(test_data[0])])
      accuracies.append(acc)
      # print metrics.confusion_matrix(test_data[1], clf.predict(test_data[0]))
      # print metrics.f1_score(test_data[1], clf.predict(test_data[0]))
   return accuracies


def do_active_learn(strategy):
   all_accuracies = []
   for triali in range(args.trials):
      ndays = args.days + 1
      # include a final day for testing.
      priors = [min(1., max(0., u.rand.gauss(args.mean, args.variance)))
                for i in range(args.days)] + [args.mean]
      data = generate_examples(ndays * 100, 100, ndays, priors,
                               ninformative=2, nclusters_per_class=2)
      clf = linear_model.LogisticRegression()
      # train on first and last instance from day 0, then remove that day
      labeled = [None, None]
      labeled[0] = data[0][0][[0,-1]]
      labeled[1] = data[0][1][[0,-1]]
      clf.fit(labeled[0][[0,-1]], labeled[1][[0,-1]])
      test_data = data[-1]
      data = data[1:-1]
      strategy_f = getattr(sys.modules[__name__], strategy)
      accuracies = active_learn(data, labeled, test_data, clf, strategy_f, args.iters)
      print 'strategy=%s trial=%d acc=%.3f' % (strategy, triali, np.average(accuracies))
      all_accuracies.append(accuracies)
   return np.mean(all_accuracies, axis=0)


def main():
   strategies = ['uncertainty', 'random', 'balanced']
   all_results = []
   for strategy in strategies:
      all_results.append(do_active_learn(strategy))
   for strategy, results in zip(strategies, all_results):
      plt.plot(results, label=strategy)
   plt.legend(loc='lower right')
   plt.show()

try:
   args = u.parse_args(ap)
   u.configure(None)

   if (__name__ == '__main__'):
      main()

except testable.Unittests_Only_Exception:
   testable.register('')
   import doctest
   doctest.testmod()
   # --unittest # hack to get test.sh to run these doctests
